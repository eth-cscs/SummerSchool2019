{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet5: a Convolutional Neural Network success story\n",
    "\n",
    "In this notebook, you will apply a famous Convolutional Neural Network, LeNet5, to the MNIST dataset. Most of the work will be *exactly* as for the MNIST MLP notebook... thus you will now see a lot of blank code blocks! Do not worry, and take code from the previous notebooks when you are stuck! \n",
    "\n",
    "# 1. Setting up the environment\n",
    "OK, you cannot exactly know what you will need to run this notebook, thus we help you! Here is what you need to import..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import Adadelta, Adam, SGD\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The data: MNIST dataset\n",
    "We load the MNIST dataset, as in the previous notebook, but then, we need to pad the images with an empty margin, because LeNet5, the CNN we will implement, needs 32x32 images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(X_train_, y_train), (X_test_, y_test) = mnist.load_data()\n",
    "\n",
    "# Padding the images, to meet the correct LeNet5 input shape (see below)\n",
    "X_train = np.pad(X_train_, ((0,0),(2,2),(2,2)), 'constant')\n",
    "X_test  = np.pad(X_test_, ((0,0),(2,2),(2,2)), 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to extract the usual information from the dataset, and also turn `y_train` and `y_test` into one-hot-encoded vectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "# TODO assign the right values to these variables\n",
    "n_train_samples = \n",
    "img_rows = \n",
    "img_cols = \n",
    "n_test_samples  = \n",
    "\n",
    "print(\"Training dataset: {} images, each one of size {}x{} pixels\".format(n_train_samples, img_rows, img_cols))\n",
    "print(\"Test dataset: {} images\".format(n_test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing the data\n",
    "Same as before, remember: input to our CNN will have to consist of floating point arrays with values between 0 and 1. This time you don't need to vectorize the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is something new! In the previous notebooks, we were using MLPs, which take vectors as images. In this notebook, we use Convolutional Neural Networks, which actually use four-dimensional tensors as input! As you probably remember, there are two formats, commonly used for CNN data: `NCWH` and `NWHC`, also known as `channels_first` or `channels_last`. Thus, you will have to reshape the CNN inputs, namely `X_train` and `X_test`.\n",
    "The MNIST data is loaded as a three-dimensional arary, and if we had to describe its format, we would say it is `NWH`. Let us reshape it! To do so, we define the variable `input_shape` based on the needed format, then, we simply reshape our input data.\n",
    "\n",
    "Hint: remember that our data is given in gray scale, thus it only has `1` channel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: assign the right input shape for both cases, channels_first (NCWH) and channels_last (NWHC)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = \n",
    "else:\n",
    "    input_shape = \n",
    "\n",
    "\n",
    "X_train = X_train.reshape(n_train_samples, input_shape[0], input_shape[1], input_shape[2])\n",
    "X_test = X_test.reshape(n_test_samples, input_shape[0], input_shape[1], input_shape[2])\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualizing the data\n",
    "Well, not so much to do here. You can shamelessly copy-paste from the previous notebook, or simply skip this part! Let's just put an empty code block here, you know, just in case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Applying a Neural Network to the problem\n",
    "This time, you will walk into the footsteps of AI pioneers Yann LeCun, Yoshua Bengio, and others, and you will replicate their breakthrough network, _LeNet5_.\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network#LeNet-5):\n",
    ">LeNet-5, a pioneering 7-level convolutional network by LeCun et al. in 1998, that classifies digits, was applied by several banks to recognize hand-written numbers on checks (British English: cheques) digitized in 32x32 pixel images. The ability to process higher resolution images requires larger and more layers of convolutional neural networks, so this technique is constrained by the availability of computing resources. \n",
    "\n",
    "Here is a picture explaining what the architecture looks like:\n",
    "![](scratch/imgs/lenet5.png)\n",
    "\n",
    "Four hints:\n",
    "\n",
    "- There is no padding in the convolutions.\n",
    "- The number before the `@` symbol is the number of channels of the layer.\n",
    "- Subsampling is `AveragePooling2D`. Even though other types of poolings might be acceptable...\n",
    "- You cannot use the output of a convolutional layer as input for a fully connected layer, you will have to put a `Flatten()` layer inbetween.\n",
    "- Remember to compile the model! You can use the usual loss function and metrics. As optimizer, Adadelta or Adam with standard parameters will be fine.\n",
    "\n",
    "If you have time, or need more details, why not take a look at the original cornerstone paper? [Here is a link to it](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5 = keras.Sequential()\n",
    "lenet5.name='Lenet5'\n",
    "\n",
    "#TODO create the Lenet5 convolutional neural network! \n",
    "# Remember that `kernel_size` is a tuple, representing width and height of the filters!\n",
    "\n",
    "first_layer_kernel_size = (3,3)\n",
    "first_layer_num_filters = 6\n",
    "lenet5.add(Conv2D(filters=first_layer_num_filters,\n",
    "                  kernel_size=first_layer_kernel_size,\n",
    "                  activation='relu', input_shape=input_shape))\n",
    "#TODO add all other layers\n",
    "\n",
    "lenet5.add(Dense(units=n_classes, activation = 'softmax'))\n",
    "\n",
    "#TODO compile the model. As optimizer, use 'Adadelta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the model summary and check that is as you expected it to be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the training parameters, and start the `fit` function! Then, check the test accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs     = 20\n",
    "\n",
    "#TODO call the fit function\n",
    "history_callback = \n",
    "\n",
    "score = lenet5.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Bonus! Visualizing the layer activations\n",
    "In this last section, we visualize the activation levels of each layer. To do this, we start by dissecting the model. We first isolate the output of the layers which maintain the spatial information of the image (for Lenet5 this means the first four layers, can you say why?). Then, we create a model which takes those layers, sends in an input and get out an output... as if we were just ignoring the layer after the ones we referenced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the outputs of the top 4 layers (those which keep the spatial information)\n",
    "layer_outputs = [layer.output for layer in lenet5.layers[:4]]\n",
    "# Create a model that will return these outputs, given the model input\n",
    "activation_model = keras.models.Model(inputs=lenet5.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select an image, and we take a slice of the test set, corresponding to that image only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 9793\n",
    "\n",
    "img_tensor = X_test[image_index:image_index+1]\n",
    "activations = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we plot the activation of each layer! What do you see? Can you understand what each layer specialized into? Check with different images to get a better understanding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, activation in enumerate(activations):\n",
    "    fig=plt.figure(figsize=(80,10));\n",
    "    for j in range((activation).shape[1]):\n",
    "        plt.subplot(1, (activation).shape[1], j+1);\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            plt.matshow(activation[0, j, :, :], cmap='gray', fignum=False);\n",
    "        else:\n",
    "            plt.matshow(activation[0, :, :, j], cmap='gray', fignum=False);\n",
    "        plt.axis('off')\n",
    "    fig.suptitle(lenet5.layers[i].name, fontsize=80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is your turn! Take LeNet5 to the next level! Create a new, improved model, based on LeNet5. Consider you have way more computational power than the authors had in 1998! Can you beat their test accuracy? You can plot the data contained in `history_callback` to have a better idea of what happened at training time... here is an empty code block to get you started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use this block as a scratchpad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Optional assignment (to do once you're satisfied with your network)\n",
    "In their paper, the authors show the samples which were mis-classified by the network. Can you do the same here? Are the mistakes understandable? Some functions you might want to use: `predict_classes` from Keras ([look here!](https://keras.io/models/model/)) and from NumPy you might find useful\n",
    "- `!=` can be used for component-wise comparison of equal sized tensors\n",
    "- `where` ([here!](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.where.html))\n",
    "- `squeeze` ([here!](https://docs.scipy.org/doc/numpy/reference/generated/numpy.squeeze.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO find mis-classified samples and plot them!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
