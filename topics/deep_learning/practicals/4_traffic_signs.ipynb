{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign classification with Convolutional Neural Networks\n",
    "\n",
    "In this notebook, you will face the real-world problem of automatically classify traffic signs. You will learn advanced techniques, such as image augmentation and learning rate scheduling, and it will be a good benchmark to assess your understanding of Convolutional Neural Networks.\n",
    "\n",
    "# 1. Setting up the environment\n",
    "For simplicity, we will import almost all packages you need in this first codeblock. Notice that we define a `data_format` string which holds the data format (or image ordering) used by Keras. We will use it to load the appropriate pre-defined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_CLASSES = 43\n",
    "IMG_SIZE = 48\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_format = 'NCWH'\n",
    "else:\n",
    "    data_format = 'NWHC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The data: GTSRB dataset\n",
    "\n",
    "From [GTSRB's website](benchmark.ini.rub.de/?section=gtsrb):\n",
    ">_The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:_\n",
    "- _Single-image, multi-class classification problem_\n",
    "- _More than 40 classes_\n",
    "- _More than 50,000 images in total_\n",
    "- _Large, lifelike database_\n",
    "\n",
    "We will use a pre-processed version of the dataset, which we stored on scratch for NCHW format. The data is stored as an HDF5 file, thus we will use `h5py` to load it. We then also split the data in train and validation sets, using 20% of the original dataset for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'scratch/data/X_'+data_format+'.h5'\n",
    "\n",
    "with  h5py.File(train_filename) as hf: \n",
    "    X, Y = hf['imgs'][:], hf['labels'][:]\n",
    "print(\"Loaded images from {}\".format(train_filename))\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a separate file for the test dataset, which we load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename = 'scratch/data/X_'+data_format+'_test.h5'\n",
    "\n",
    "with  h5py.File(test_filename) as hf: \n",
    "    X_test, Y_test = hf['imgs'][:], hf['labels'][:]\n",
    "print(\"Loaded images from {}\".format(test_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the dataset, extract some stats, like number of images and check that `X_train`, `X_val`, `X_test` and their labels are as you expect them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO assign the right values to these variables\n",
    "n_train_samples = \n",
    "input_shape     = \n",
    "output_dim      = \n",
    "\n",
    "print(\"{} train samples\".format(n_train_samples))\n",
    "print(\"Input dimension: {} \".format(input_dim))\n",
    "print(\"Output dimension: {}\".format(output_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing the data\n",
    "\n",
    "Nothing to do here! The data has already been prepared for us. If you are interested, here is the function which was used to prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central crop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    if data_format == 'NCWH':\n",
    "        img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualizing the data\n",
    "\n",
    "Go ahead and explore the dataset a little further! Use `plt.imshow` to show some samples, but be careful, because the function expects images in `NWHC` format, thus you will probably have to use `np.transpose` ([here](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.transpose.html)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "#TODO use plt.imshow to display one or more samples from the datasets!\n",
    "\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Applying Neural Networks to the problem\n",
    "\n",
    "We need to classify images, thus we most likely want to start from Convolutional Neural Networks! This time, a starting CNN is given for you, just be careful, it expects the variable `input_shape` to hold the shape of the input images (you should have defined this above), and you have to assign the right value to `output_dim`, which will be the dimension of the NN output. Now take time to analyze the CNN and write down the output dimensions and the number of parameters of each layer (take a piece of paper, or open a separate text file in this lab). Once you are done, add the classic call to `model.summary()` and see if it matches your expectations! \n",
    "\n",
    "As you see, we created a function which returns the CNN. This will be helpful later, when we will change training strategy and add data augmentation, without touching the NN topology!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    output_dim = NUM_CLASSES\n",
    "        \n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=input_shape,\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "#TODO: call summary() only after you've written down parameter count and output shape for each layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to compile the network! We start with a simple SGD optimizer, which we initialized with non-default parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train the model using SGD + Nesterov momentum\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# TODO compile the model, using the optimizer we just defined, with optimizer=sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still one thing to do before training the network! We define a `lr_schedule` callback, which will return a learning rate `lr` based on the epoch, and will be called by Keras, at training time, at the beginning of each epoch. As it is defined now, it would just return a constant learning rate, but it would not lead to good accuracy. Modify the function so that it multiplies the initial learning rate by a factor of $0.1^{\\lfloor epochs/10 \\rfloor}$, where $\\lfloor \\cdot \\rfloor$ is the floor operator, i.e. rounding towards the smallest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    #TODO return a reduce the learning rate by a factor of 10 each 10 epochs\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All callbacks are passed to the `fit` function through an array, which must contain callback objects. In our case, we create an object of type `LearningRateScheduler` which takes as argument the function we just defined. That's all!\n",
    "\n",
    "Let's start the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_callback=model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_val, Y_val),\n",
    "          callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, very high numbers, aren't they? What about the test accuracy? Go ahead and check it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO use model.evaluate with the test dataset to obtain test accuracy\n",
    "score = \n",
    "\n",
    "print(\"Test accuracy = {}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy should be lower than the train and validation ones. OK, can we do better? Well, the data set is small, even if wer keep training, we will not have enough samples to acheve better generalization, thus, we look at something different: data augmentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data augmentation in Keras\n",
    "\n",
    "In Keras, we cak use `ImageDataGenerator`, which takes an array of images and applies random transformations to them. We can define some parameters for such transformations. [Look at the documentation](https://keras.io/preprocessing/image/), and understand what type of modifications we are introducing in the code block below, and why we need to call `datagen.fit`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ImageDataGenerator` does not only modify the images. It also acts as a generator, which yields batches of samples which can be consumed by the training functions. In the code block below, we use the function `flow` to get the first batch (properly transposed, so that we can easily display it below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_format == 'NCWH':\n",
    "    X_aug = np.transpose(datagen.flow(X_train, batch_size=32, shuffle=False)[0][0:5], (0, 2, 3, 1))\n",
    "else:\n",
    "    X_aug = datagen.flow(X_train, batch_size=32, shuffle=False)[0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, `X_aug` holds the augmented versions of the first `5` train images. Plot the images and their augmented counterparts side to side and see what types of transformations have been applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,25))\n",
    "for i in range(5):\n",
    "    plt.subplot(5,2,2*i+1)\n",
    "    # TODO use imshow to display the i-th original image (in NWHC format!)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.subplot(5,2,2*i+2)\n",
    "    # TODO use imshow to display the augmented image\n",
    "    \n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go up by two code blocks, run the augmentation again and plot the resulting images. What happened? \n",
    "\n",
    "Well, the augmented images should be different from the previous ones, that's because the generator has applied a new set of random transformations to them. At training time, at every epoch, images will be slightly different, and this will help the network to focus on relevant features (and generalize much better). Let's do the training again and see what happens! First we re-initialize the model weights, by re-instantiating and compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize models \n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "# TODO compile the model again, using the previously defined sgd optimizer again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start the training. Instead of the function `fit`, which would feed the network samples taken from the original image tensors, we use `fit_generator`, which takes a generator as argument. Obviously, we will use our image augmenting generator. Let's see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_history_callback = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, get the test accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO use model.evaluate with the test dataset to obtain test accuracy\n",
    "score = \n",
    "\n",
    "print(\"Test accuracy = {}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have reached a higher test accuracy, congratulations! Plot convergence data from `history_callback` and `aug_history_callback` and see how the two training curves differ... can you understand why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot training curves!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can play around with the network, or adapt the code from previous notebook and visualize the activation for the 2D layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
